#!/usr/bin/env python3
"""
HR çŸ¥è­˜åº«æ™ºèƒ½æŸ¥è©¢ç³»çµ± - Streamlit éƒ¨ç½²ç‰ˆæœ¬

æ”¯æ´è³‡æ–™ä¾†æºï¼š
- å‹å‹•æ³•è¦ FAQï¼ˆå‹å‹•éƒ¨ã€å‹ä¿å±€ã€è·å®‰ç½²ï¼‰
- å‹å‹•æ¥­å‹™èªªæ˜
- ç¨…å‹™å•ç­”ï¼ˆç¶œåˆæ‰€å¾—ç¨…ï¼‰
- å¥ä¿æ¥­å‹™ï¼ˆæŠ•ä¿èˆ‡ä¿è²»ï¼‰
- æ³•è¦æ¢æ–‡ï¼ˆå…¨åœ‹æ³•è¦è³‡æ–™åº«ï¼‰
"""

import streamlit as st
import os
import time
import json
from typing import List, Dict, Any
from pathlib import Path

# é é¢é…ç½®
st.set_page_config(
    page_title="äººè³‡æ³•è¦æ™ºèƒ½æŸ¥è©¢",
    page_icon="ğŸ‘·",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Store é…ç½®ï¼ˆ4 å€‹ Storeï¼‰
STORES = {
    # === å‹å‹•æ³•è¦ ===
    'labor_faq': {
        'name': 'krepo-labor-faq',
        'store_id': 'fileSearchStores/krepolaborfaq-sak7us3cm6pd',
        'display_name': 'å‹å‹•æ³•è¦FAQ',
        'icon': 'ğŸ‘·',
        'description': 'å‹å‹•éƒ¨ã€å‹ä¿å±€ã€è·å®‰ç½²å¸¸è¦‹å•ç­”',
        'count': 1487,
        'group': 'labor',
    },
    'labor_articles': {
        'name': 'krepo-labor-articles',
        'store_id': 'fileSearchStores/krepolaborarticles-piho4qc46y5s',
        'display_name': 'å‹å‹•èˆ‡å¥ä¿æ¥­å‹™',
        'icon': 'ğŸ“‹',
        'description': 'å‹å‹•éƒ¨æ¥­å‹™å°ˆå€ã€å‹ä¿å±€ä¿éšªæ¥­å‹™ã€å¥ä¿æŠ•ä¿èªªæ˜',
        'count': 228,
        'group': 'labor',
    },
    # === ç¨…å‹™ ===
    'tax_faq': {
        'name': 'krepo-tax-faq',
        'store_id': 'fileSearchStores/krepotaxfaq-lbafhhfsjlsd',
        'display_name': 'ç¨…å‹™å•ç­”',
        'icon': 'ğŸ’°',
        'description': 'ç¶œåˆæ‰€å¾—ç¨…å•èˆ‡ç­”',
        'count': 318,
        'group': 'tax',
    },
    # === æ³•è¦ ===
    'law_articles': {
        'name': 'krepo-law-articles',
        'store_id': 'fileSearchStores/krepolawarticles-5ai9q1awe7al',
        'display_name': 'æ³•è¦æ¢æ–‡',
        'icon': 'ğŸ“–',
        'description': 'å…¨æ°‘å¥åº·ä¿éšªæ³•ç­‰æ³•è¦æ¢æ–‡',
        'count': 193,
        'group': 'law',
    },
}


def load_mappings():
    """
    è¼‰å…¥ gemini_mappings ç›®éŒ„ä¸‹çš„æ˜ å°„æª”æ¡ˆ

    æ ¼å¼: {doc_id: {gemini_file_id, store_id, source, title, date, original_url, uploaded_at}}
    """
    mappings_path = Path(__file__).parent.parent / "data" / "gemini_mappings"

    gemini_id_mapping = {}  # gemini_short_id -> doc_id
    file_mapping = {}       # doc_id -> info

    mapping_files = [
        "krepo-labor-faq.json",
        "krepo-labor-articles.json",
        "krepo-tax-faq.json",
        "krepo-law-articles.json",
    ]

    try:
        for filename in mapping_files:
            filepath = mappings_path / filename
            if filepath.exists():
                with open(filepath, 'r', encoding='utf-8') as f:
                    raw_mapping = json.load(f)
                    for doc_id, info in raw_mapping.items():
                        # å»ºç«‹ gemini_id -> doc_id æ˜ å°„
                        gemini_file_id = info.get('gemini_file_id', '')
                        if gemini_file_id:
                            short_id = gemini_file_id.replace('files/', '')
                            gemini_id_mapping[short_id] = doc_id

                        # å»ºç«‹ doc_id -> info æ˜ å°„
                        file_mapping[doc_id] = {
                            'display_name': info.get('title', ''),
                            'date': info.get('date', ''),
                            'source': info.get('source', ''),
                            'store_id': info.get('store_id', ''),
                            'original_url': info.get('original_url', ''),
                        }

    except Exception as e:
        st.warning(f"è¼‰å…¥ mapping æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    return gemini_id_mapping, file_mapping


# å…¨åŸŸ Mapping (è¼‰å…¥ä¸€æ¬¡)
GEMINI_ID_MAPPING, FILE_MAPPING = load_mappings()


def resolve_source_display_name(raw_id: str) -> tuple:
    """
    å°‡ Gemini å›å‚³çš„ file ID è§£æç‚ºå¯è®€çš„é¡¯ç¤ºåç¨±

    å›å‚³: (display_name, source_type, date, original_url)
    """
    # å…ˆæª¢æŸ¥ raw_id æ˜¯å¦ç›´æ¥æ˜¯ doc_id
    if raw_id in FILE_MAPPING:
        doc_id = raw_id
    else:
        # å˜—è©¦å¾ gemini_id -> doc_id æ˜ å°„æŸ¥è©¢
        doc_id = GEMINI_ID_MAPPING.get(raw_id, '')

    if doc_id and doc_id in FILE_MAPPING:
        info = FILE_MAPPING[doc_id]
        display_name = info.get('display_name', '')
        date = info.get('date', 'æœªçŸ¥æ—¥æœŸ')
        source = info.get('source', '')
        original_url = info.get('original_url', '')

        # åˆ¤æ–·ä¾†æºé¡å‹å’Œåœ–æ¨™
        if 'mol_faq' in source:
            source_type = "å‹å‹•éƒ¨FAQ"
            icon = "ğŸ‘·"
        elif 'bli_faq' in source:
            source_type = "å‹ä¿å±€FAQ"
            icon = "ğŸ¢"
        elif 'osha_faq' in source:
            source_type = "è·å®‰ç½²FAQ"
            icon = "âš ï¸"
        elif 'mol_business' in source:
            source_type = "å‹å‹•éƒ¨æ¥­å‹™"
            icon = "ğŸ“‹"
        elif 'bli_insurance' in source:
            source_type = "å‹ä¿å±€æ¥­å‹™"
            icon = "ğŸ“„"
        elif 'individual_income_tax' in source:
            source_type = "ç¨…å‹™å•ç­”"
            icon = "ğŸ’°"
        elif 'insurance_premium' in source:
            source_type = "å¥ä¿æ¥­å‹™"
            icon = "ğŸ¥"
        elif 'law_articles' in source:
            source_type = "æ³•è¦æ¢æ–‡"
            icon = "ğŸ“–"
        else:
            source_type = "æœªçŸ¥"
            icon = "ğŸ“„"

        # æ ¼å¼åŒ–é¡¯ç¤ºåç¨±
        if display_name:
            # æˆªæ–·éé•·çš„æ¨™é¡Œ
            short_title = display_name[:40] + "..." if len(display_name) > 40 else display_name
            return f"{icon} {short_title}", source_type, date, original_url

        return f"{icon} {source_type}_{date}", source_type, date, original_url

    # å¦‚æœ mapping æ‰¾ä¸åˆ°
    return f"ğŸ“„ {raw_id[:30]}...", "æœªçŸ¥", "æœªçŸ¥æ—¥æœŸ", ""


# ç¯„ä¾‹å•é¡Œ
EXAMPLE_QUESTIONS = [
    "å‹å·¥é€€ä¼‘é‡‘æç¹³ç‡æ˜¯å¤šå°‘ï¼Ÿ",
    "è³‡é£è²»å¦‚ä½•è¨ˆç®—ï¼Ÿ",
    "è‚²å¬°ç•™è·åœè–ªæœŸé–“å¥ä¿æ€éº¼è™•ç†ï¼Ÿ",
    "åŠ ç­è²»è¦å¦‚ä½•è¨ˆç®—ï¼Ÿ",
    "è·ç½è£œå„Ÿæœ‰å“ªäº›é …ç›®ï¼Ÿ",
    "æ‰£ç¹³æ†‘å–®ä»€éº¼æ™‚å€™è¦ç”³å ±ï¼Ÿ",
]


def get_system_prompt(selected_stores: List[str]) -> str:
    """
    æ ¹æ“šé¸å–çš„ Store çµ„åˆç”¢ç”Ÿç³»çµ±æç¤º
    """
    base_prompt = """ä½ æ˜¯å°ˆæ¥­çš„ HR æ³•è¦é¡§å•ï¼Œç†Ÿæ‚‰å°ç£å‹å‹•æ³•è¦ã€ç¨…å‹™è¦å®šèˆ‡å¥ä¿åˆ¶åº¦ã€‚

è«‹æ ¹æ“šåƒè€ƒè³‡æ–™å›ç­”å•é¡Œã€‚

å›ç­”æ™‚å¿…é ˆï¼š
1. æ˜ç¢ºå¼•ç”¨ä¾†æºæ–‡ä»¶
2. å¦‚æœè³‡æ–™ä¸­æ²’æœ‰ç›¸é—œè³‡è¨Šï¼Œè«‹èª å¯¦èªªæ˜
3. ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”
4. ä¿æŒå°ˆæ¥­ã€å®¢è§€çš„æ…‹åº¦
"""

    # æ ¹æ“šé¸å–çš„ Store åŠ å…¥ç‰¹å®šæŒ‡å¼•
    specific_guidelines = []

    if 'labor_faq' in selected_stores:
        specific_guidelines.append("""
ã€å‹å‹•æ³•è¦FAQæŒ‡å¼•ã€‘
- ç›´æ¥å¼•ç”¨å¸¸è¦‹å•ç­”å…§å®¹
- èªªæ˜ç›¸é—œæ³•è¦ä¾æ“š
- åˆ—å‡ºé©ç”¨å°è±¡å’Œæ¢ä»¶""")

    if 'labor_articles' in selected_stores:
        specific_guidelines.append("""
ã€å‹å‹•æ¥­å‹™èªªæ˜æŒ‡å¼•ã€‘
- è§£é‡‹æ¥­å‹™æµç¨‹å’Œè¦å®š
- èªªæ˜ç”³è«‹æ–¹å¼å’Œæ¢ä»¶
- åˆ—å‡ºæ‰€éœ€æ–‡ä»¶""")

    if 'tax_faq' in selected_stores:
        specific_guidelines.append("""
ã€ç¨…å‹™å•ç­”æŒ‡å¼•ã€‘
- è§£é‡‹ç¨…å‹™è¦å®š
- èªªæ˜ç”³å ±æ–¹å¼å’ŒæœŸé™
- åˆ—å‡ºå…ç¨…æˆ–æ¸›ç¨…æ¢ä»¶""")

    if 'nhi_insurance' in selected_stores:
        specific_guidelines.append("""
ã€å¥ä¿æ¥­å‹™æŒ‡å¼•ã€‘
- èªªæ˜æŠ•ä¿è³‡æ ¼å’Œæ¢ä»¶
- è§£é‡‹ä¿è²»è¨ˆç®—æ–¹å¼
- èªªæ˜ç¹³è²»è¦å®š""")

    if 'law_articles' in selected_stores:
        specific_guidelines.append("""
ã€æ³•è¦æ¢æ–‡æŒ‡å¼•ã€‘
- å¼•ç”¨å®Œæ•´çš„æ³•æ¢å…§å®¹
- èªªæ˜æ³•æ¢çš„é©ç”¨æƒ…æ³""")

    if specific_guidelines:
        return base_prompt + "\n" + "\n".join(specific_guidelines)
    return base_prompt


def query_gemini(
    question: str,
    selected_stores: List[str],
    api_key: str,
    model: str = 'gemini-2.5-flash'
) -> Dict[str, Any]:
    """
    ä½¿ç”¨ Gemini File Search åŸ·è¡ŒæŸ¥è©¢
    """
    from google import genai
    from google.genai import types

    client = genai.Client(api_key=api_key)

    # å–å¾—é¸å–çš„ Store IDs
    store_ids = [STORES[s]['store_id'] for s in selected_stores if s in STORES and STORES[s]['store_id']]

    if not store_ids:
        return {
            'answer': 'è«‹è‡³å°‘é¸æ“‡ä¸€å€‹è³‡æ–™ä¾†æºï¼ˆæˆ– Store å°šæœªè¨­å®šï¼‰',
            'sources': [],
            'error': True,
            'empty_answer': False
        }

    # å–å¾—ç³»çµ±æç¤º
    system_prompt = get_system_prompt(selected_stores)

    start_time = time.time()

    try:
        response = client.models.generate_content(
            model=model,
            contents=question,
            config=types.GenerateContentConfig(
                tools=[
                    types.Tool(
                        file_search=types.FileSearch(
                            file_search_store_names=store_ids
                        )
                    )
                ],
                temperature=0.1,
                max_output_tokens=8000,
                system_instruction=system_prompt
            )
        )

        latency = time.time() - start_time

        # æå–ç­”æ¡ˆ
        answer = None
        empty_answer = True
        if hasattr(response, 'text') and response.text:
            answer = response.text
            empty_answer = False

        # æå–ä¾†æº
        sources = extract_sources(response)

        return {
            'answer': answer,
            'sources': sources,
            'latency': latency,
            'error': False,
            'empty_answer': empty_answer,
        }

    except Exception as e:
        return {
            'answer': f'æŸ¥è©¢å¤±æ•—: {str(e)}',
            'sources': [],
            'error': True,
            'empty_answer': False
        }


def extract_sources(response) -> List[Dict[str, Any]]:
    """
    å¾ Gemini å›æ‡‰ä¸­æå–ä¾†æºï¼ˆå·²å»é‡ï¼‰
    """
    sources = []
    seen_ids = set()

    try:
        if hasattr(response, 'candidates') and len(response.candidates) > 0:
            candidate = response.candidates[0]

            if hasattr(candidate, 'grounding_metadata') and candidate.grounding_metadata:
                metadata = candidate.grounding_metadata

                if hasattr(metadata, 'grounding_chunks') and metadata.grounding_chunks:
                    for chunk in metadata.grounding_chunks:
                        if hasattr(chunk, 'retrieved_context'):
                            context = chunk.retrieved_context

                            # æå–åŸå§‹æª”å/ID
                            raw_id = ""
                            if hasattr(context, 'title') and context.title:
                                raw_id = context.title
                            elif hasattr(context, 'uri') and context.uri:
                                raw_id = context.uri.split('/')[-1]

                            # å»é‡
                            if raw_id in seen_ids:
                                continue
                            seen_ids.add(raw_id)

                            # ä½¿ç”¨ mapping è§£æé¡¯ç¤ºåç¨±
                            display_name, source_type, date, original_url = resolve_source_display_name(raw_id)

                            snippet = ""
                            if hasattr(context, 'text') and context.text:
                                snippet = context.text[:500]

                            score = 1.0
                            if hasattr(chunk, 'score'):
                                score = float(chunk.score)

                            sources.append({
                                'filename': display_name,
                                'raw_id': raw_id,
                                'source_type': source_type,
                                'date': date,
                                'snippet': snippet,
                                'score': score,
                                'original_url': original_url,
                            })

    except Exception as e:
        st.warning(f"æå–ä¾†æºæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    return sources


def render_sidebar():
    """æ¸²æŸ“å´é‚Šæ¬„"""
    with st.sidebar:
        st.header("ğŸ“Š è³‡æ–™ä¾†æº")

        # é¸æ“‡å…¨éƒ¨ / å–æ¶ˆé¸æ“‡ æŒ‰éˆ•
        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ… å…¨é¸", use_container_width=True):
                for key in STORES.keys():
                    st.session_state[f"store_{key}"] = True
                st.rerun()
        with col2:
            if st.button("âŒ å–æ¶ˆ", use_container_width=True):
                for key in STORES.keys():
                    st.session_state[f"store_{key}"] = False
                st.rerun()

        st.markdown("---")

        selected_stores = []

        # === å‹å‹•æ³•è¦ ===
        st.caption("ğŸ‘· å‹å‹•æ³•è¦")
        for key, store in STORES.items():
            if store.get('group') != 'labor':
                continue
            default_value = (key == 'labor_faq') if f"store_{key}" not in st.session_state else None
            checked = st.checkbox(
                f"{store['icon']} {store['display_name']} ({store['count']:,})",
                value=default_value if default_value is not None else None,
                key=f"store_{key}",
                help=store['description']
            )
            if checked:
                selected_stores.append(key)

        st.markdown("---")

        # === ç¨…å‹™ ===
        st.caption("ğŸ’° ç¨…å‹™")
        for key, store in STORES.items():
            if store.get('group') != 'tax':
                continue
            checked = st.checkbox(
                f"{store['icon']} {store['display_name']} ({store['count']:,})",
                key=f"store_{key}",
                help=store['description']
            )
            if checked:
                selected_stores.append(key)

        st.markdown("---")

        # === æ³•è¦ ===
        st.caption("ğŸ“– æ³•è¦æ¢æ–‡")
        for key, store in STORES.items():
            if store.get('group') != 'law':
                continue
            checked = st.checkbox(
                f"{store['icon']} {store['display_name']} ({store['count']:,})",
                key=f"store_{key}",
                help=store['description']
            )
            if checked:
                selected_stores.append(key)

        st.markdown("---")

        # é¡¯ç¤ºé¸å–çš„è³‡æ–™çµ±è¨ˆ
        if selected_stores:
            total_docs = sum(STORES[s]['count'] for s in selected_stores)
            st.metric("ğŸ“š æ–‡ä»¶ç¸½æ•¸", f"{total_docs:,}")
        else:
            st.warning("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹è³‡æ–™ä¾†æº")

        st.markdown("---")

        # ä½¿ç”¨èªªæ˜
        st.header("ğŸ“– ä½¿ç”¨èªªæ˜")
        st.markdown("""
1. **é¸æ“‡è³‡æ–™ä¾†æº**ï¼šå‹¾é¸è¦æŸ¥è©¢çš„çŸ¥è­˜åº«
2. **è¼¸å…¥å•é¡Œ**ï¼šåœ¨ä¸»ç•«é¢è¼¸å…¥æ‚¨çš„å•é¡Œ
3. **é»æ“ŠæŸ¥è©¢**ï¼šAI æœƒå¾é¸å–çš„çŸ¥è­˜åº«ä¸­æœå°‹ç›¸é—œè³‡æ–™ä¸¦å›ç­”
4. **æŸ¥çœ‹ä¾†æº**ï¼šå±•é–‹åƒè€ƒä¾†æºå¯æŸ¥çœ‹åŸå§‹å…§å®¹
""")

    return selected_stores


def main():
    """ä¸»ç¨‹å¼"""
    # å–å¾— API Key
    api_key = st.secrets.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")

    if not api_key:
        st.error("è«‹è¨­å®š GEMINI_API_KEY")
        st.stop()

    # æ¸²æŸ“å´é‚Šæ¬„
    selected_stores = render_sidebar()

    # ä¸»æ¨™é¡Œ
    st.title("ğŸ‘· äººè³‡æ³•è¦æ™ºèƒ½æŸ¥è©¢")
    st.caption("âš ï¸ æœ¬ç³»çµ±ç‚ºå±•ç¤ºç”¨ï¼Œå¦‚é‡ç•«é¢ç„¡åæ‡‰ï¼Œè«‹é‡æ–°æ•´ç†é é¢")

    # å•é¡Œè¼¸å…¥
    if 'current_question' not in st.session_state:
        st.session_state.current_question = ""

    question = st.text_area(
        "è«‹è¼¸å…¥æ‚¨çš„å•é¡Œï¼š",
        value=st.session_state.current_question,
        placeholder="ä¾‹å¦‚ï¼šè³‡é£è²»å¦‚ä½•è¨ˆç®—ï¼Ÿ",
        height=100
    )

    # æŒ‰éˆ•åˆ—
    col1, col2, col3 = st.columns([1, 1, 4])

    with col1:
        submit_button = st.button("ğŸ” æŸ¥è©¢", type="primary", use_container_width=True)

    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…é™¤", use_container_width=True):
            st.session_state.current_question = ""
            st.rerun()

    # è™•ç†æŸ¥è©¢
    if submit_button and question:
        if not selected_stores:
            st.error("è«‹è‡³å°‘é¸æ“‡ä¸€å€‹è³‡æ–™ä¾†æº")
        else:
            with st.spinner("ğŸ” AI æŸ¥è©¢ä¸­..."):
                result = query_gemini(
                    question,
                    selected_stores,
                    api_key
                )

            if result['error']:
                st.error(result['answer'])
            elif result['empty_answer'] or not result['sources']:
                st.warning("âš ï¸ æŸ¥è©¢æœªèƒ½å–å¾—æœ‰æ•ˆå›ç­”")
                st.info("è«‹å˜—è©¦æ›å€‹æ–¹å¼æè¿°æ‚¨çš„å•é¡Œã€‚")
            else:
                # é¡¯ç¤ºçµæœ
                st.success("âœ… æŸ¥è©¢å®Œæˆ")

                stores_text = ", ".join([STORES[s]['display_name'] for s in selected_stores])
                st.caption(f"â±ï¸ å›æ‡‰æ™‚é–“: {result['latency']:.2f} ç§’ã€€ï½œã€€ğŸ“š ä¾†æºæ•¸é‡: {len(result['sources'])} ç­†ã€€ï½œã€€ğŸ“‚ æŸ¥è©¢ç¯„åœ: {stores_text}")

                st.markdown("---")

                # ç­”æ¡ˆ
                st.subheader("ğŸ“ ç­”æ¡ˆ")
                st.markdown(result['answer'])

                st.markdown("---")

                # ä¾†æºï¼ˆå»é‡è¤‡ï¼‰
                if result['sources']:
                    # ä»¥ filename å»é‡è¤‡
                    seen_filenames = set()
                    unique_sources = []
                    for source in result['sources']:
                        if source['filename'] not in seen_filenames:
                            seen_filenames.add(source['filename'])
                            unique_sources.append(source)

                    st.subheader(f"ğŸ“š åƒè€ƒä¾†æº ({len(unique_sources)} ç­†)")

                    # æŒ‰é¡å‹åˆ†çµ„
                    source_groups = {}
                    for source in unique_sources:
                        stype = source.get('source_type', 'æœªçŸ¥')
                        if stype not in source_groups:
                            source_groups[stype] = []
                        source_groups[stype].append(source)

                    # é¡¯ç¤ºå„çµ„
                    for stype, sources_list in source_groups.items():
                        st.caption(f"{stype} ({len(sources_list)} ç­†)")
                        for source in sources_list:
                            with st.expander(f"{source['filename']}", expanded=False):
                                st.markdown(f"**ç›¸é—œå…§å®¹ï¼š**")
                                st.markdown(f"> {source['snippet'][:300]}...")

                                if source.get('original_url'):
                                    st.markdown(f"[ğŸ”— æŸ¥çœ‹åŸå§‹ç¶²é ]({source['original_url']})")

    # ç¯„ä¾‹å•é¡Œ
    if not question:
        st.markdown("---")
        st.subheader("ğŸ’¡ ç¯„ä¾‹å•é¡Œ")

        cols = st.columns(2)
        for idx, eq in enumerate(EXAMPLE_QUESTIONS):
            col = cols[idx % 2]
            with col:
                if st.button(f"ğŸ“Œ {eq}", key=f"example_{idx}", use_container_width=True):
                    st.session_state.current_question = eq
                    st.rerun()

    # é å°¾
    st.divider()
    st.caption("è³‡æ–™ä¾†æºï¼šæ„è—è³‡è¨Šå‹å‹•çŸ¥è­˜åº«")


if __name__ == "__main__":
    main()
